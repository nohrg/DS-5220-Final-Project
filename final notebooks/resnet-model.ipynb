{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MURA Binary Classification\n",
    "## Pretrained Model: ResNet - Specialised/Unified Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.027884Z",
     "iopub.status.busy": "2024-11-30T00:07:10.026948Z",
     "iopub.status.idle": "2024-11-30T00:07:10.032937Z",
     "shell.execute_reply": "2024-11-30T00:07:10.032072Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.027849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.034948Z",
     "iopub.status.busy": "2024-11-30T00:07:10.034578Z",
     "iopub.status.idle": "2024-11-30T00:07:10.046289Z",
     "shell.execute_reply": "2024-11-30T00:07:10.045391Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.034911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/input/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.055211Z",
     "iopub.status.busy": "2024-11-30T00:07:10.054969Z",
     "iopub.status.idle": "2024-11-30T00:07:10.059629Z",
     "shell.execute_reply": "2024-11-30T00:07:10.058752Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.055188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/input/mura-data/MURA-v1.1'\n",
    "\n",
    "# #train\n",
    "# train_images = pd.DataFrame(pd.read_csv(path + '/train_image_paths.csv', header = None, names =['image_path']))\n",
    "# train_studies = pd.DataFrame(pd.read_csv(path + '/train_labeled_studies.csv', header= None, names=['study_path', 'label']))\n",
    "\n",
    "# #test\n",
    "# test_images = pd.DataFrame(pd.read_csv(path + '/valid_image_paths.csv', header = None, names =['image_path']))\n",
    "# test_studies = pd.DataFrame(pd.read_csv(path + '/valid_labeled_studies.csv', header= None, names=['study_path', 'label']))\n",
    "\n",
    "# train_images['study_label'] = train_images['image_path'].str.rsplit('/', n=2, expand=True)[1].str.rsplit('_', n=1, expand=True)[1]\n",
    "# test_images['study_label'] = test_images['image_path'].str.rsplit('/', n=2, expand=True)[1].str.rsplit('_', n=1, expand=True)[1]\n",
    "\n",
    "# train_images['label'] = train_images['study_label'].map({'positive': 1, 'negative': 0})\n",
    "# test_images['label'] = test_images['study_label'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# train_images['XR'] = train_images['image_path'].str.rsplit('/', n=5, expand=True)[2]\n",
    "# test_images['XR'] = test_images['image_path'].str.rsplit('/', n=5, expand=True)[2]\n",
    "\n",
    "# prefix = '/kaggle/input/mura-data/'\n",
    "# train_images['image_path'] = prefix + train_images['image_path']\n",
    "# test_images['image_path'] = prefix + test_images['image_path']\n",
    "\n",
    "# train_images['image_size'] = train_images['image_path'].apply(lambda path: Image.open(path).size)\n",
    "# test_images['image_size'] = test_images['image_path'].apply(lambda path: Image.open(path).size)\n",
    "\n",
    "# # train_images.to_csv('train_df.csv', index=False)\n",
    "# # test_images.to_csv('val_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.061505Z",
     "iopub.status.busy": "2024-11-30T00:07:10.061271Z",
     "iopub.status.idle": "2024-11-30T00:07:10.213214Z",
     "shell.execute_reply": "2024-11-30T00:07:10.212489Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.061482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load 2 DataFrames directly\n",
    "train_data = pd.read_csv('/kaggle/input/load-mura/train_df.csv')\n",
    "test_images = pd.read_csv('/kaggle/input/load-mura/val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.214684Z",
     "iopub.status.busy": "2024-11-30T00:07:10.214337Z",
     "iopub.status.idle": "2024-11-30T00:07:10.230215Z",
     "shell.execute_reply": "2024-11-30T00:07:10.229394Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.214647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_images, val_images = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print('Number of images in training set:', len(train_images))\n",
    "print('Number of images in validation set:', len(val_images))\n",
    "print('Number of images in test set:', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.232475Z",
     "iopub.status.busy": "2024-11-30T00:07:10.232186Z",
     "iopub.status.idle": "2024-11-30T00:07:10.248210Z",
     "shell.execute_reply": "2024-11-30T00:07:10.247344Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.232449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.249382Z",
     "iopub.status.busy": "2024-11-30T00:07:10.249171Z",
     "iopub.status.idle": "2024-11-30T00:07:10.260805Z",
     "shell.execute_reply": "2024-11-30T00:07:10.259875Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.249356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_images['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.262023Z",
     "iopub.status.busy": "2024-11-30T00:07:10.261753Z",
     "iopub.status.idle": "2024-11-30T00:07:10.267411Z",
     "shell.execute_reply": "2024-11-30T00:07:10.266727Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.261983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# prefix = '/kaggle/input/mura-data/'\n",
    "# image_paths = train_images['image_path'].tolist() \n",
    "# image_sizes = [Image.open(prefix + path).size for path in image_paths]\n",
    "# unique_sizes = set(image_sizes)\n",
    "# if len(unique_sizes) == 1:\n",
    "#     print(\"All images are the same size:\", unique_sizes.pop())\n",
    "# else:\n",
    "#     print(f\"Images have different sizes. Unique sizes found: {unique_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:07:10.268724Z",
     "iopub.status.busy": "2024-11-30T00:07:10.268440Z",
     "iopub.status.idle": "2024-11-30T00:07:10.316908Z",
     "shell.execute_reply": "2024-11-30T00:07:10.316379Z",
     "shell.execute_reply.started": "2024-11-30T00:07:10.268671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img = Image.open('/kaggle/input/mura-data/MURA-v1.1/train/XR_FOREARM/patient09241/study1_positive/image2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:09:44.809446Z",
     "iopub.status.busy": "2024-11-30T00:09:44.808677Z",
     "iopub.status.idle": "2024-11-30T00:09:46.057840Z",
     "shell.execute_reply": "2024-11-30T00:09:46.056972Z",
     "shell.execute_reply.started": "2024-11-30T00:09:44.809409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (for pre-trained models)\n",
    "])\n",
    "\n",
    "# Define augmentations for the minor class\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def plot_random_images(df, label, n=5):\n",
    "    images = df[df['label'] == label]['image_path'].sample(n) \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i, path in enumerate(images):\n",
    "        img = Image.open(path)\n",
    "        img_rgb = img.convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "        \n",
    "        transformed_tensor = augmentation_transform(img_rgb) # transform(img_rgb)\n",
    "        transformed_img = transformed_tensor.numpy().transpose((1, 2, 0))  # Convert tensor back to image format\n",
    "        transformed_img = transformed_img.clip(0, 1)  # Clip values to range [0, 1]\n",
    "        \n",
    "        plt.subplot(1, n, i + 1)\n",
    "        \n",
    "        # plt.imshow(img)\n",
    "        plt.imshow(transformed_img)\n",
    "        \n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Show samples for each class\n",
    "for label in train_images['label'].unique():\n",
    "    plot_random_images(train_images, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:30.877637Z",
     "iopub.status.busy": "2024-11-30T00:10:30.877312Z",
     "iopub.status.idle": "2024-11-30T00:10:30.884174Z",
     "shell.execute_reply": "2024-11-30T00:10:30.883366Z",
     "shell.execute_reply.started": "2024-11-30T00:10:30.877610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show image by index\n",
    "def plot_one_image(df, index):\n",
    "    path = df.loc[index, 'image_path']\n",
    "    label = df.loc[index, 'label']\n",
    "    img = Image.open(path)\n",
    "    img_rgb = img.convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "    transformed_tensor = transform(img_rgb)\n",
    "    transformed_img = transformed_tensor.numpy().transpose((1, 2, 0))  # Convert tensor back to image format\n",
    "    transformed_img = transformed_img.clip(0, 1)  # Clip values to range [0, 1]\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'original image, label:{label}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(transformed_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('transformed image')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:33.298898Z",
     "iopub.status.busy": "2024-11-30T00:10:33.298542Z",
     "iopub.status.idle": "2024-11-30T00:10:33.547329Z",
     "shell.execute_reply": "2024-11-30T00:10:33.546530Z",
     "shell.execute_reply.started": "2024-11-30T00:10:33.298867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot_one_image(train_images, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:40.783720Z",
     "iopub.status.busy": "2024-11-30T00:10:40.782908Z",
     "iopub.status.idle": "2024-11-30T00:10:40.792918Z",
     "shell.execute_reply": "2024-11-30T00:10:40.791915Z",
     "shell.execute_reply.started": "2024-11-30T00:10:40.783675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_images['XR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:46.952809Z",
     "iopub.status.busy": "2024-11-30T00:10:46.952118Z",
     "iopub.status.idle": "2024-11-30T00:10:46.962604Z",
     "shell.execute_reply": "2024-11-30T00:10:46.961748Z",
     "shell.execute_reply.started": "2024-11-30T00:10:46.952777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # On seperate classes\n",
    "# which_class = 'XR_HAND' # XR_WRIST  XR_SHOULDER   XR_HAND  XR_FINGER   XR_ELBOW    XR_FOREARM  XR_HUMERUS \n",
    "# train_df = train_images[train_images['XR'] == which_class]\n",
    "# val_df = val_images[val_images['XR'] == which_class]\n",
    "# test_df = test_images[test_images['XR'] == which_class]\n",
    "\n",
    "# On the whole dataset\n",
    "train_df = train_images\n",
    "val_df = val_images\n",
    "test_df = test_images\n",
    "\n",
    "print(train_df['label'].value_counts())\n",
    "print(val_df['label'].value_counts())\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:49.316109Z",
     "iopub.status.busy": "2024-11-30T00:10:49.315637Z",
     "iopub.status.idle": "2024-11-30T00:10:49.322782Z",
     "shell.execute_reply": "2024-11-30T00:10:49.321892Z",
     "shell.execute_reply.started": "2024-11-30T00:10:49.316075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the standard transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (for pre-trained models)\n",
    "])\n",
    "\n",
    "# Define augmentations for the minor class\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Custom Dataset class to handle loading and transformations\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"This class is for validation and test datasets\"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Perform data augmentation on training dataset\n",
    "class BalancedImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, augment_transform=None):\n",
    "        self.df_major = df[df['label'] == 0]  # Majority class (label=0)\n",
    "        self.df_minor = df[df['label'] == 1]  # Minority class (label=1)\n",
    "        self.transform = transform\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "        # Balance the dataset by augmenting the minor class\n",
    "        num_major = len(self.df_major)\n",
    "        num_minor = len(self.df_minor)\n",
    "        self.augmented_minor_df = self.df_minor.sample(n=num_major, replace=True, random_state=42)\n",
    "\n",
    "        # Combine the majority and augmented minority dataframes\n",
    "        self.balanced_df = pd.concat([self.df_major, self.augmented_minor_df]).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.balanced_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.balanced_df.iloc[idx]['image_path']\n",
    "        label = self.balanced_df.iloc[idx]['label']\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply augmentations to the minor class\n",
    "        if label == 1 and self.augment_transform:\n",
    "            image = self.augment_transform(image)\n",
    "        elif self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:10:51.789129Z",
     "iopub.status.busy": "2024-11-30T00:10:51.788347Z",
     "iopub.status.idle": "2024-11-30T00:10:51.793980Z",
     "shell.execute_reply": "2024-11-30T00:10:51.793047Z",
     "shell.execute_reply.started": "2024-11-30T00:10:51.789091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create dataset and data loader\n",
    "# train_dataset = BalancedImageDataset(train_df, transform=transform, augment_transform=augmentation_transform)\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Adjust batch_size as needed\n",
    "\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # Adjust batch_size as needed\n",
    "\n",
    "test_dataset = ImageDataset(test_df, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:13:26.618948Z",
     "iopub.status.busy": "2024-11-30T00:13:26.618454Z",
     "iopub.status.idle": "2024-11-30T00:13:26.815272Z",
     "shell.execute_reply": "2024-11-30T00:13:26.814351Z",
     "shell.execute_reply.started": "2024-11-30T00:13:26.618912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show the transformed images\n",
    "def show_image(img_tensor, title=None):\n",
    "    \"\"\"\n",
    "    Display a single image from a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    img = img_tensor.numpy().transpose((1, 2, 0))  # Convert CxHxW to HxWxC\n",
    "    plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Access an image and its label\n",
    "img_tensor, label = train_dataset[1]\n",
    "\n",
    "# Display the image\n",
    "show_image(img_tensor, title=f\"Label: {label}\")\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:13:42.734039Z",
     "iopub.status.busy": "2024-11-30T00:13:42.733299Z",
     "iopub.status.idle": "2024-11-30T00:13:42.744564Z",
     "shell.execute_reply": "2024-11-30T00:13:42.743740Z",
     "shell.execute_reply.started": "2024-11-30T00:13:42.734005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module): # 70s for 1 epoch\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)  \n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class BinaryImageClassifierCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryImageClassifierCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                \n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),             \n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)                  \n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),                                        \n",
    "            nn.Linear(14 * 14 * 256, 512),                       \n",
    "            nn.ReLU(),\n",
    "           # nn.Dropout(0.5),                                    \n",
    "            nn.Linear(512, 1)                           \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)  # Pass through convolutional layers\n",
    "        x = self.fc_layers(x)    # Pass through fully connected layers\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T20:17:32.564504Z",
     "iopub.status.busy": "2024-12-05T20:17:32.564236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "num_classes = 2  \n",
    "# model = BinaryImageClassifierCNN() #SimpleCNN()\n",
    "\n",
    "# ResNet-Deeper-----------------------------------\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "num_features = resnet.fc.in_features\n",
    "print(num_features)\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_features, 256), \n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.Linear(32, 1),  # Binary classification\n",
    "    # nn.Sigmoid()  # To output probabilities\n",
    ")\n",
    "# -----------------------------------------\n",
    "print(resnet.fc)\n",
    "# # ResNet-----------------------------------\n",
    "# resnet = models.resnet18(pretrained=True)\n",
    "# num_features = resnet.fc.in_features\n",
    "# print(num_features)\n",
    "# resnet.fc = nn.Sequential(\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(num_features, 256), \n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(256, 64),\n",
    "#     nn.Linear(64, 1),  # Binary classification\n",
    "#     # nn.Sigmoid()  # To output probabilities\n",
    "# )\n",
    "# # -----------------------------------------\n",
    "\n",
    "# # Load model\n",
    "# resnet = torch.load('/kaggle/input/resnet18-on-wrist-acc80/resnet18_model.pth') # Load model trained on WRIST\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion =  nn.BCEWithLogitsLoss() #For Binary classification we use logit loss# For multi-class: nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.8, weight_decay=0.001)\n",
    "\n",
    "# # Try L2 in optimizer\n",
    "# params = [\n",
    "#     {\"params\": [param for name, param in resnet.named_parameters() if \"bias\" not in name], \"weight_decay\": 0.01},\n",
    "#     {\"params\": [param for name, param in resnet.named_parameters() if \"bias\" in name], \"weight_decay\": 0.0}\n",
    "# ]\n",
    "# optimizer = optim.Adam(params, lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze(1)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predicted = (probabilities > 0.5).long()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Save model\"\"\"\n",
    "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after the last improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "            path (str): Path to save the best model.\n",
    "            verbose (bool): Print a message when stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves the model when validation loss decreases.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
    "        torch.save(model, self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# class EarlyStopping:\n",
    "#     \"\"\"Not save model\"\"\"\n",
    "#     def __init__(self, patience=5, delta=0, verbose=False):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             patience (int): How long to wait after the last improvement.\n",
    "#             delta (float): Minimum change to qualify as an improvement.\n",
    "#             verbose (bool): Print a message when stopping.\n",
    "#         \"\"\"\n",
    "#         self.patience = patience\n",
    "#         self.delta = delta\n",
    "#         self.verbose = verbose\n",
    "#         self.counter = 0\n",
    "#         self.best_score = None\n",
    "#         self.early_stop = False\n",
    "#         self.val_loss_min = np.Inf\n",
    "\n",
    "#     def __call__(self, val_loss):\n",
    "#         score = -val_loss\n",
    "\n",
    "#         if self.best_score is None:\n",
    "#             self.best_score = score\n",
    "#             self.val_loss_min = val_loss  # Track the best validation loss\n",
    "#         elif score < self.best_score + self.delta:\n",
    "#             self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "#             if self.counter >= self.patience:\n",
    "#                 self.early_stop = True\n",
    "#         else:\n",
    "#             self.best_score = score\n",
    "#             self.val_loss_min = val_loss  # Update the best validation loss\n",
    "#             self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:14:17.408265Z",
     "iopub.status.busy": "2024-11-30T00:14:17.407240Z",
     "iopub.status.idle": "2024-11-30T00:14:17.665253Z",
     "shell.execute_reply": "2024-11-30T00:14:17.664351Z",
     "shell.execute_reply.started": "2024-11-30T00:14:17.408227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "import time\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_dataloader,val_dataloader, criterion, optimizer, num_epochs=10):\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        preds, labels = [], []\n",
    "        for images, label in iter(train_dataloader):\n",
    "            images, label = images.to(device), label.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).squeeze(1)\n",
    "           \n",
    "            loss = criterion(outputs, label)\n",
    "            # Accumulate the loss\n",
    "            running_loss += loss.item()\n",
    "      \n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            pred = (probabilities > 0.5).long() \n",
    "            preds.append(pred.detach().cpu().numpy())     \n",
    "            labels.append(label.detach().cpu().numpy())\n",
    "             \n",
    "        # train_acc    \n",
    "        preds = np.hstack(preds)\n",
    "        labels = np.hstack(labels)\n",
    "        train_acc.append(accuracy_score(labels, preds))\n",
    "        \n",
    "        # train_loss\n",
    "        loss = running_loss / len(train_dataloader)\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        # Perform validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds, targets = [], []\n",
    "            running_loss = 0\n",
    "            for images, label in iter(val_dataloader):\n",
    "                images, label = images.to(device), label.to(device).float()\n",
    "\n",
    "                outputs = model(images).squeeze(1)\n",
    "\n",
    "                loss = criterion(outputs, label)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Calculate val_acc\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                pred = (probabilities > 0.5).long()  # For binary classification\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "                targets.append(label.detach().cpu().numpy())\n",
    "        \n",
    "            preds = np.hstack(preds)\n",
    "            targets = np.hstack(targets)\n",
    "        \n",
    "        val_acc.append(accuracy_score(targets, preds))\n",
    "        val_loss.append(running_loss / len(val_dataloader))\n",
    "        \n",
    "        # Check early stopping\n",
    "        early_stopping(val_loss[-1], model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        spent_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss[-1]:.4f}, Validation Loss: {val_loss[-1]:.4f}. Spent {spent_time:.4f}s.\")\n",
    "        \n",
    "    print(\"Training complete.\")\n",
    "    return train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:14:23.435613Z",
     "iopub.status.busy": "2024-11-30T00:14:23.434676Z",
     "iopub.status.idle": "2024-11-30T00:23:49.666084Z",
     "shell.execute_reply": "2024-11-30T00:23:49.665092Z",
     "shell.execute_reply.started": "2024-11-30T00:14:23.435566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "num_epochs = 20\n",
    "train_loss, train_acc, val_loss, val_acc = train_model(resnet, train_dataloader,val_dataloader, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:23:57.999155Z",
     "iopub.status.busy": "2024-11-30T00:23:57.998551Z",
     "iopub.status.idle": "2024-11-30T00:23:58.314135Z",
     "shell.execute_reply": "2024-11-30T00:23:58.313254Z",
     "shell.execute_reply.started": "2024-11-30T00:23:57.999121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss curves\n",
    "plt.plot(np.arange(1, len(train_loss) + 1), train_loss,'b-', label='training loss')\n",
    "plt.plot(np.arange(1, len(val_loss) + 1), val_loss,'r-', label='validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend(loc='best')\n",
    "plt.title('The Loss Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:24:01.276544Z",
     "iopub.status.busy": "2024-11-30T00:24:01.276205Z",
     "iopub.status.idle": "2024-11-30T00:24:01.499714Z",
     "shell.execute_reply": "2024-11-30T00:24:01.498890Z",
     "shell.execute_reply.started": "2024-11-30T00:24:01.276514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Accuracy curves\n",
    "plt.plot(np.arange(1, len(train_acc) + 1), train_acc,'g-', label='training accuracy')\n",
    "plt.plot(np.arange(1, len(val_acc) + 1), val_acc,'m-', label='validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracies')\n",
    "plt.legend(loc='best')  \n",
    "plt.title('The Accuracy Curves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "def calculate_kappa(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze(1)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predicted = (probabilities > 0.5).long()\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate Cohen's kappa\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "    print(f\"Cohen's Kappa: {kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:24:10.950517Z",
     "iopub.status.busy": "2024-11-30T00:24:10.950168Z",
     "iopub.status.idle": "2024-11-30T00:24:23.757529Z",
     "shell.execute_reply": "2024-11-30T00:24:23.756576Z",
     "shell.execute_reply.started": "2024-11-30T00:24:10.950486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate after training\n",
    "evaluate_model(resnet, test_dataloader)\n",
    "calculate_kappa(resnet, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:25:42.574869Z",
     "iopub.status.busy": "2024-11-30T00:25:42.574514Z",
     "iopub.status.idle": "2024-11-30T00:25:42.693386Z",
     "shell.execute_reply": "2024-11-30T00:25:42.691725Z",
     "shell.execute_reply.started": "2024-11-30T00:25:42.574839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(resnet, 'resnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load checkpoint.pt\n",
    "model = torch.load('/kaggle/working/checkpoint.pt')\n",
    "\n",
    "# Evaluate the best one with early stopping\n",
    "evaluate_model(model, test_dataloader)\n",
    "\n",
    "# Evaluate the best one with early stopping\n",
    "calculate_kappa(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T00:26:20.670988Z",
     "iopub.status.busy": "2024-11-30T00:26:20.670604Z",
     "iopub.status.idle": "2024-11-30T00:26:26.486898Z",
     "shell.execute_reply": "2024-11-30T00:26:26.485963Z",
     "shell.execute_reply.started": "2024-11-30T00:26:20.670959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = torch.load('/kaggle/working/resnet18_model.pth')\n",
    "# evaluate_model(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6071688,
     "sourceId": 9887033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6165122,
     "sourceId": 10013779,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6201257,
     "sourceId": 10062700,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
