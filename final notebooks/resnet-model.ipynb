{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9887033,"sourceType":"datasetVersion","datasetId":6071688},{"sourceId":10013779,"sourceType":"datasetVersion","datasetId":6165122},{"sourceId":10062700,"sourceType":"datasetVersion","datasetId":6201257}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport random\nfrom PIL import Image\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.026948Z","iopub.execute_input":"2024-11-30T00:07:10.027884Z","iopub.status.idle":"2024-11-30T00:07:10.032937Z","shell.execute_reply.started":"2024-11-30T00:07:10.027849Z","shell.execute_reply":"2024-11-30T00:07:10.032072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir('/kaggle/input/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.034578Z","iopub.execute_input":"2024-11-30T00:07:10.034948Z","iopub.status.idle":"2024-11-30T00:07:10.046289Z","shell.execute_reply.started":"2024-11-30T00:07:10.034911Z","shell.execute_reply":"2024-11-30T00:07:10.045391Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# path = '/kaggle/input/mura-data/MURA-v1.1'\n\n# #train\n# train_images = pd.DataFrame(pd.read_csv(path + '/train_image_paths.csv', header = None, names =['image_path']))\n# train_studies = pd.DataFrame(pd.read_csv(path + '/train_labeled_studies.csv', header= None, names=['study_path', 'label']))\n\n# #test\n# test_images = pd.DataFrame(pd.read_csv(path + '/valid_image_paths.csv', header = None, names =['image_path']))\n# test_studies = pd.DataFrame(pd.read_csv(path + '/valid_labeled_studies.csv', header= None, names=['study_path', 'label']))\n\n# train_images['study_label'] = train_images['image_path'].str.rsplit('/', n=2, expand=True)[1].str.rsplit('_', n=1, expand=True)[1]\n# test_images['study_label'] = test_images['image_path'].str.rsplit('/', n=2, expand=True)[1].str.rsplit('_', n=1, expand=True)[1]\n\n# train_images['label'] = train_images['study_label'].map({'positive': 1, 'negative': 0})\n# test_images['label'] = test_images['study_label'].map({'positive': 1, 'negative': 0})\n\n# train_images['XR'] = train_images['image_path'].str.rsplit('/', n=5, expand=True)[2]\n# test_images['XR'] = test_images['image_path'].str.rsplit('/', n=5, expand=True)[2]\n\n# prefix = '/kaggle/input/mura-data/'\n# train_images['image_path'] = prefix + train_images['image_path']\n# test_images['image_path'] = prefix + test_images['image_path']\n\n# train_images['image_size'] = train_images['image_path'].apply(lambda path: Image.open(path).size)\n# test_images['image_size'] = test_images['image_path'].apply(lambda path: Image.open(path).size)\n\n# # train_images.to_csv('train_df.csv', index=False)\n# # test_images.to_csv('val_df.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.054969Z","iopub.execute_input":"2024-11-30T00:07:10.055211Z","iopub.status.idle":"2024-11-30T00:07:10.059629Z","shell.execute_reply.started":"2024-11-30T00:07:10.055188Z","shell.execute_reply":"2024-11-30T00:07:10.058752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load 2 DataFrames directly\ntrain_data = pd.read_csv('/kaggle/input/load-mura/train_df.csv')\ntest_images = pd.read_csv('/kaggle/input/load-mura/val_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.061271Z","iopub.execute_input":"2024-11-30T00:07:10.061505Z","iopub.status.idle":"2024-11-30T00:07:10.213214Z","shell.execute_reply.started":"2024-11-30T00:07:10.061482Z","shell.execute_reply":"2024-11-30T00:07:10.212489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images, val_images = train_test_split(train_data, test_size=0.2, random_state=42)\nprint('Number of images in training set:', len(train_images))\nprint('Number of images in validation set:', len(val_images))\nprint('Number of images in test set:', len(test_images))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.214337Z","iopub.execute_input":"2024-11-30T00:07:10.214684Z","iopub.status.idle":"2024-11-30T00:07:10.230215Z","shell.execute_reply.started":"2024-11-30T00:07:10.214647Z","shell.execute_reply":"2024-11-30T00:07:10.229394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.232186Z","iopub.execute_input":"2024-11-30T00:07:10.232475Z","iopub.status.idle":"2024-11-30T00:07:10.248210Z","shell.execute_reply.started":"2024-11-30T00:07:10.232449Z","shell.execute_reply":"2024-11-30T00:07:10.247344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_images['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.249171Z","iopub.execute_input":"2024-11-30T00:07:10.249382Z","iopub.status.idle":"2024-11-30T00:07:10.260805Z","shell.execute_reply.started":"2024-11-30T00:07:10.249356Z","shell.execute_reply":"2024-11-30T00:07:10.259875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prefix = '/kaggle/input/mura-data/'\n# image_paths = train_images['image_path'].tolist() \n# image_sizes = [Image.open(prefix + path).size for path in image_paths]\n# unique_sizes = set(image_sizes)\n# if len(unique_sizes) == 1:\n#     print(\"All images are the same size:\", unique_sizes.pop())\n# else:\n#     print(f\"Images have different sizes. Unique sizes found: {unique_sizes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.261753Z","iopub.execute_input":"2024-11-30T00:07:10.262023Z","iopub.status.idle":"2024-11-30T00:07:10.267411Z","shell.execute_reply.started":"2024-11-30T00:07:10.261983Z","shell.execute_reply":"2024-11-30T00:07:10.266727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = Image.open('/kaggle/input/mura-data/MURA-v1.1/train/XR_FOREARM/patient09241/study1_positive/image2.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.268440Z","iopub.execute_input":"2024-11-30T00:07:10.268724Z","iopub.status.idle":"2024-11-30T00:07:10.316908Z","shell.execute_reply.started":"2024-11-30T00:07:10.268671Z","shell.execute_reply":"2024-11-30T00:07:10.316379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the image transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (for pre-trained models)\n])\n\n# Define augmentations for the minor class\naugmentation_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndef plot_random_images(df, label, n=5):\n    images = df[df['label'] == label]['image_path'].sample(n) \n    plt.figure(figsize=(15, 15))\n    for i, path in enumerate(images):\n        img = Image.open(path)\n        img_rgb = img.convert(\"RGB\")  # Ensure the image is in RGB mode\n        \n        transformed_tensor = augmentation_transform(img_rgb) # transform(img_rgb)\n        transformed_img = transformed_tensor.numpy().transpose((1, 2, 0))  # Convert tensor back to image format\n        transformed_img = transformed_img.clip(0, 1)  # Clip values to range [0, 1]\n        \n        plt.subplot(1, n, i + 1)\n        \n        # plt.imshow(img)\n        plt.imshow(transformed_img)\n        \n        plt.title(label)\n        plt.axis('off')\n    plt.show()\n\n# Show samples for each class\nfor label in train_images['label'].unique():\n    plot_random_images(train_images, label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:09:44.808677Z","iopub.execute_input":"2024-11-30T00:09:44.809446Z","iopub.status.idle":"2024-11-30T00:09:46.057840Z","shell.execute_reply.started":"2024-11-30T00:09:44.809409Z","shell.execute_reply":"2024-11-30T00:09:46.056972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show image by index\ndef plot_one_image(df, index):\n    path = df.loc[index, 'image_path']\n    label = df.loc[index, 'label']\n    img = Image.open(path)\n    img_rgb = img.convert(\"RGB\")  # Ensure the image is in RGB mode\n    transformed_tensor = transform(img_rgb)\n    transformed_img = transformed_tensor.numpy().transpose((1, 2, 0))  # Convert tensor back to image format\n    transformed_img = transformed_img.clip(0, 1)  # Clip values to range [0, 1]\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f'original image, label:{label}')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(transformed_img)\n    plt.axis('off')\n    plt.title('transformed image')\n    \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:30.877312Z","iopub.execute_input":"2024-11-30T00:10:30.877637Z","iopub.status.idle":"2024-11-30T00:10:30.884174Z","shell.execute_reply.started":"2024-11-30T00:10:30.877610Z","shell.execute_reply":"2024-11-30T00:10:30.883366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plot_one_image(train_images, 200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:33.298542Z","iopub.execute_input":"2024-11-30T00:10:33.298898Z","iopub.status.idle":"2024-11-30T00:10:33.547329Z","shell.execute_reply.started":"2024-11-30T00:10:33.298867Z","shell.execute_reply":"2024-11-30T00:10:33.546530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images['XR'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:40.782908Z","iopub.execute_input":"2024-11-30T00:10:40.783720Z","iopub.status.idle":"2024-11-30T00:10:40.792918Z","shell.execute_reply.started":"2024-11-30T00:10:40.783675Z","shell.execute_reply":"2024-11-30T00:10:40.791915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # On seperate classes\n# which_class = 'XR_HAND' # XR_WRIST  XR_SHOULDER   XR_HAND  XR_FINGER   XR_ELBOW    XR_FOREARM  XR_HUMERUS \n# train_df = train_images[train_images['XR'] == which_class]\n# val_df = val_images[val_images['XR'] == which_class]\n# test_df = test_images[test_images['XR'] == which_class]\n\n# On the whole dataset\ntrain_df = train_images\nval_df = val_images\ntest_df = test_images\n\nprint(train_df['label'].value_counts())\nprint(val_df['label'].value_counts())\nprint(test_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:46.952118Z","iopub.execute_input":"2024-11-30T00:10:46.952809Z","iopub.status.idle":"2024-11-30T00:10:46.962604Z","shell.execute_reply.started":"2024-11-30T00:10:46.952777Z","shell.execute_reply":"2024-11-30T00:10:46.961748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Define the standard transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (for pre-trained models)\n])\n\n# Define augmentations for the minor class\naugmentation_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Custom Dataset class to handle loading and transformations\nclass ImageDataset(Dataset):\n    \"\"\"This class is for validation and test datasets\"\"\"\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx]['image_path']\n        label = self.df.iloc[idx]['label']\n\n        # Load image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Perform data augmentation on training dataset\nclass BalancedImageDataset(Dataset):\n    def __init__(self, df, transform=None, augment_transform=None):\n        self.df_major = df[df['label'] == 0]  # Majority class (label=0)\n        self.df_minor = df[df['label'] == 1]  # Minority class (label=1)\n        self.transform = transform\n        self.augment_transform = augment_transform\n\n        # Balance the dataset by augmenting the minor class\n        num_major = len(self.df_major)\n        num_minor = len(self.df_minor)\n        self.augmented_minor_df = self.df_minor.sample(n=num_major, replace=True, random_state=42)\n\n        # Combine the majority and augmented minority dataframes\n        self.balanced_df = pd.concat([self.df_major, self.augmented_minor_df]).reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.balanced_df)\n\n    def __getitem__(self, idx):\n        img_path = self.balanced_df.iloc[idx]['image_path']\n        label = self.balanced_df.iloc[idx]['label']\n\n        # Load image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Apply augmentations to the minor class\n        if label == 1 and self.augment_transform:\n            image = self.augment_transform(image)\n        elif self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:49.315637Z","iopub.execute_input":"2024-11-30T00:10:49.316109Z","iopub.status.idle":"2024-11-30T00:10:49.322782Z","shell.execute_reply.started":"2024-11-30T00:10:49.316075Z","shell.execute_reply":"2024-11-30T00:10:49.321892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create dataset and data loader\n# train_dataset = BalancedImageDataset(train_df, transform=transform, augment_transform=augmentation_transform)\ntrain_dataset = ImageDataset(train_df, transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Adjust batch_size as needed\n\nval_dataset = ImageDataset(val_df, transform=transform)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # Adjust batch_size as needed\n\ntest_dataset = ImageDataset(test_df, transform=transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Adjust batch_size as needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:10:51.788347Z","iopub.execute_input":"2024-11-30T00:10:51.789129Z","iopub.status.idle":"2024-11-30T00:10:51.793980Z","shell.execute_reply.started":"2024-11-30T00:10:51.789091Z","shell.execute_reply":"2024-11-30T00:10:51.793047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show the transformed images\ndef show_image(img_tensor, title=None):\n    \"\"\"\n    Display a single image from a PyTorch tensor.\n    \"\"\"\n    img = img_tensor.numpy().transpose((1, 2, 0))  # Convert CxHxW to HxWxC\n    plt.imshow(img)\n    if title:\n        plt.title(title)\n    plt.axis('off')\n    plt.show()\n\n# Access an image and its label\nimg_tensor, label = train_dataset[1]\n\n# Display the image\nshow_image(img_tensor, title=f\"Label: {label}\")\nprint(img_tensor.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:13:26.618454Z","iopub.execute_input":"2024-11-30T00:13:26.618948Z","iopub.status.idle":"2024-11-30T00:13:26.815272Z","shell.execute_reply.started":"2024-11-30T00:13:26.618912Z","shell.execute_reply":"2024-11-30T00:13:26.814351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nclass SimpleCNN(nn.Module): # 70s for 1 epoch\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 56 * 56, 128)  \n        self.fc2 = nn.Linear(128, 1)\n        self.dropout = nn.Dropout(0.5)  \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 56 * 56)  \n        x = F.relu(self.fc1(x))\n        # x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\nclass BinaryImageClassifierCNN(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifierCNN, self).__init__()\n        \n        # Convolutional layers\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),                \n\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),             \n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),                 \n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)                  \n        )\n        \n        # Fully connected layers\n        self.fc_layers = nn.Sequential(\n            nn.Flatten(),                                        \n            nn.Linear(14 * 14 * 256, 512),                       \n            nn.ReLU(),\n           # nn.Dropout(0.5),                                    \n            nn.Linear(512, 1)                           \n        )\n    \n    def forward(self, x):\n        x = self.conv_layers(x)  # Pass through convolutional layers\n        x = self.fc_layers(x)    # Pass through fully connected layers\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:13:42.733299Z","iopub.execute_input":"2024-11-30T00:13:42.734039Z","iopub.status.idle":"2024-11-30T00:13:42.744564Z","shell.execute_reply.started":"2024-11-30T00:13:42.734005Z","shell.execute_reply":"2024-11-30T00:13:42.743740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\nnum_classes = 2  \n# model = BinaryImageClassifierCNN() #SimpleCNN()\n\n# ResNet-Deeper-----------------------------------\nresnet = models.resnet18(pretrained=True)\nnum_features = resnet.fc.in_features\nprint(num_features)\nresnet.fc = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(num_features, 256), \n    nn.Dropout(0.5),\n    nn.Linear(256, 128),\n    nn.Linear(128, 32),\n    nn.Linear(32, 1),  # Binary classification\n    # nn.Sigmoid()  # To output probabilities\n)\n# -----------------------------------------\nprint(resnet.fc)\n# # ResNet-----------------------------------\n# resnet = models.resnet18(pretrained=True)\n# num_features = resnet.fc.in_features\n# print(num_features)\n# resnet.fc = nn.Sequential(\n#     nn.Dropout(0.5),\n#     nn.Linear(num_features, 256), \n#     nn.Dropout(0.5),\n#     nn.Linear(256, 64),\n#     nn.Linear(64, 1),  # Binary classification\n#     # nn.Sigmoid()  # To output probabilities\n# )\n# # -----------------------------------------\n\n# # Load model\n# resnet = torch.load('/kaggle/input/resnet18-on-wrist-acc80/resnet18_model.pth') # Load model trained on WRIST\n\n# Loss function and optimizer\ncriterion =  nn.BCEWithLogitsLoss() #For Binary classification we use logit loss# For multi-class: nn.CrossEntropyLoss()\n# optimizer = optim.Adam(resnet.parameters(), lr=0.001)\noptimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.8, weight_decay=0.001)\n\n# # Try L2 in optimizer\n# params = [\n#     {\"params\": [param for name, param in resnet.named_parameters() if \"bias\" not in name], \"weight_decay\": 0.01},\n#     {\"params\": [param for name, param in resnet.named_parameters() if \"bias\" in name], \"weight_decay\": 0.0}\n# ]\n# optimizer = optim.Adam(params, lr=0.001)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:17:32.564236Z","iopub.execute_input":"2024-12-05T20:17:32.564504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():  # No need to calculate gradients during evaluation\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).squeeze(1)\n            probabilities = torch.sigmoid(outputs)\n            predicted = (probabilities > 0.5).long()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Save model\"\"\"\n    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after the last improvement.\n            delta (float): Minimum change to qualify as an improvement.\n            path (str): Path to save the best model.\n            verbose (bool): Print a message when stopping.\n        \"\"\"\n        self.patience = patience\n        self.delta = delta\n        self.path = path\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.verbose:\n                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves the model when validation loss decreases.\"\"\"\n        if self.verbose:\n            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n        torch.save(model, self.path)\n        self.val_loss_min = val_loss\n\n# class EarlyStopping:\n#     \"\"\"Not save model\"\"\"\n#     def __init__(self, patience=5, delta=0, verbose=False):\n#         \"\"\"\n#         Args:\n#             patience (int): How long to wait after the last improvement.\n#             delta (float): Minimum change to qualify as an improvement.\n#             verbose (bool): Print a message when stopping.\n#         \"\"\"\n#         self.patience = patience\n#         self.delta = delta\n#         self.verbose = verbose\n#         self.counter = 0\n#         self.best_score = None\n#         self.early_stop = False\n#         self.val_loss_min = np.Inf\n\n#     def __call__(self, val_loss):\n#         score = -val_loss\n\n#         if self.best_score is None:\n#             self.best_score = score\n#             self.val_loss_min = val_loss  # Track the best validation loss\n#         elif score < self.best_score + self.delta:\n#             self.counter += 1\n#             if self.verbose:\n#                 print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n#             if self.counter >= self.patience:\n#                 self.early_stop = True\n#         else:\n#             self.best_score = score\n#             self.val_loss_min = val_loss  # Update the best validation loss\n#             self.counter = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = model.to(device)\nresnet = resnet.to(device)\n\nimport time\n\n# Training function\ndef train_model(model, train_dataloader,val_dataloader, criterion, optimizer, num_epochs=10):\n    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n    # Initialize EarlyStopping\n    early_stopping = EarlyStopping(patience=5, verbose=True)\n    \n    for epoch in range(num_epochs):\n        start_time = time.time()\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n        preds, labels = [], []\n        for images, label in iter(train_dataloader):\n            images, label = images.to(device), label.to(device).float()\n            \n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images).squeeze(1)\n           \n            loss = criterion(outputs, label)\n            # Accumulate the loss\n            running_loss += loss.item()\n      \n\n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            probabilities = torch.sigmoid(outputs)\n            pred = (probabilities > 0.5).long() \n            preds.append(pred.detach().cpu().numpy())     \n            labels.append(label.detach().cpu().numpy())\n             \n        # train_acc    \n        preds = np.hstack(preds)\n        labels = np.hstack(labels)\n        train_acc.append(accuracy_score(labels, preds))\n        \n        # train_loss\n        loss = running_loss / len(train_dataloader)\n        \n        train_loss.append(loss)\n        \n        # Perform validation\n        model.eval()\n        with torch.no_grad():\n            preds, targets = [], []\n            running_loss = 0\n            for images, label in iter(val_dataloader):\n                images, label = images.to(device), label.to(device).float()\n\n                outputs = model(images).squeeze(1)\n\n                loss = criterion(outputs, label)\n                running_loss += loss.item()\n\n                # Calculate val_acc\n                probabilities = torch.sigmoid(outputs)\n                pred = (probabilities > 0.5).long()  # For binary classification\n                preds.append(pred.detach().cpu().numpy())\n                targets.append(label.detach().cpu().numpy())\n        \n            preds = np.hstack(preds)\n            targets = np.hstack(targets)\n        \n        val_acc.append(accuracy_score(targets, preds))\n        val_loss.append(running_loss / len(val_dataloader))\n        \n        # Check early stopping\n        early_stopping(val_loss[-1], model)\n\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n\n        spent_time = time.time() - start_time\n\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss[-1]:.4f}, Validation Loss: {val_loss[-1]:.4f}. Spent {spent_time:.4f}s.\")\n        \n    print(\"Training complete.\")\n    return train_loss, train_acc, val_loss, val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:14:17.407240Z","iopub.execute_input":"2024-11-30T00:14:17.408265Z","iopub.status.idle":"2024-11-30T00:14:17.665253Z","shell.execute_reply.started":"2024-11-30T00:14:17.408227Z","shell.execute_reply":"2024-11-30T00:14:17.664351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start training\nnum_epochs = 20\ntrain_loss, train_acc, val_loss, val_acc = train_model(resnet, train_dataloader,val_dataloader, criterion, optimizer, num_epochs=num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:14:23.434676Z","iopub.execute_input":"2024-11-30T00:14:23.435613Z","iopub.status.idle":"2024-11-30T00:23:49.666084Z","shell.execute_reply.started":"2024-11-30T00:14:23.435566Z","shell.execute_reply":"2024-11-30T00:23:49.665092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss curves\nplt.plot(np.arange(1, len(train_loss) + 1), train_loss,'b-', label='training loss')\nplt.plot(np.arange(1, len(val_loss) + 1), val_loss,'r-', label='validation loss')\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.legend(loc='best')\nplt.title('The Loss Curves')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:23:57.998551Z","iopub.execute_input":"2024-11-30T00:23:57.999155Z","iopub.status.idle":"2024-11-30T00:23:58.314135Z","shell.execute_reply.started":"2024-11-30T00:23:57.999121Z","shell.execute_reply":"2024-11-30T00:23:58.313254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy curves\nplt.plot(np.arange(1, len(train_acc) + 1), train_acc,'g-', label='training accuracy')\nplt.plot(np.arange(1, len(val_acc) + 1), val_acc,'m-', label='validation accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracies')\nplt.legend(loc='best')  \nplt.title('The Accuracy Curves')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:24:01.276205Z","iopub.execute_input":"2024-11-30T00:24:01.276544Z","iopub.status.idle":"2024-11-30T00:24:01.499714Z","shell.execute_reply.started":"2024-11-30T00:24:01.276514Z","shell.execute_reply":"2024-11-30T00:24:01.498890Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\ndef calculate_kappa(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    all_predictions = []\n    all_labels = []\n\n    with torch.no_grad():  # No need to calculate gradients during evaluation\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).squeeze(1)\n            probabilities = torch.sigmoid(outputs)\n            predicted = (probabilities > 0.5).long()\n            \n            # Collect predictions and true labels\n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate Cohen's kappa\n    kappa = cohen_kappa_score(all_labels, all_predictions)\n    print(f\"Cohen's Kappa: {kappa:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate after training\nevaluate_model(resnet, test_dataloader)\ncalculate_kappa(resnet, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:24:10.950168Z","iopub.execute_input":"2024-11-30T00:24:10.950517Z","iopub.status.idle":"2024-11-30T00:24:23.757529Z","shell.execute_reply.started":"2024-11-30T00:24:10.950486Z","shell.execute_reply":"2024-11-30T00:24:23.756576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model\ntorch.save(resnet, 'resnet_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:25:42.574514Z","iopub.execute_input":"2024-11-30T00:25:42.574869Z","iopub.status.idle":"2024-11-30T00:25:42.693386Z","shell.execute_reply.started":"2024-11-30T00:25:42.574839Z","shell.execute_reply":"2024-11-30T00:25:42.691725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load checkpoint.pt\nmodel = torch.load('/kaggle/working/checkpoint.pt')\n\n# Evaluate the best one with early stopping\nevaluate_model(model, test_dataloader)\n\n# Evaluate the best one with early stopping\ncalculate_kappa(model, test_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = torch.load('/kaggle/working/resnet18_model.pth')\n# evaluate_model(model, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:26:20.670604Z","iopub.execute_input":"2024-11-30T00:26:20.670988Z","iopub.status.idle":"2024-11-30T00:26:26.486898Z","shell.execute_reply.started":"2024-11-30T00:26:20.670959Z","shell.execute_reply":"2024-11-30T00:26:26.485963Z"}},"outputs":[],"execution_count":null}]}